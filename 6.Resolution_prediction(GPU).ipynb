{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54f395d-d77a-4506-a57f-32af598df4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optree in ./.local/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from optree) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f920a70c-f7e3-4893-81c9-69fe20b789b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "To use Keras, you need to have `optree` installed. Install it via `pip install optree`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam, SGD\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/_tf_keras/keras/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/__init__.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Import everything from /api/ into keras.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# Import * ignores names start with \"_\".\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Add everything in /api/ to the module search path.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/api/__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/api/activations/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/activations/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exponential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/activations/activations.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/backend/__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# When using the torch backend,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# torch needs to be imported first, otherwise it will segfault\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# upon import.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/backend/common/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_utils\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutocastScope\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasVariable\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/backend/common/dtypes.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m standardize_dtype\n\u001b[1;32m      7\u001b[0m BOOL_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m      8\u001b[0m INT_TYPES \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/backend/common/variables.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstateless_scope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_stateless_scope\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mKerasVariable\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Represents a backend-agnostic variable in Keras.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    A `Variable` acts as a container for state. It holds a tensor value and can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_interactive_logging\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_interactive_logging_enabled\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_visualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_to_dot\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_visualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumerical_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/model_visualization.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/tree/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_same_structure\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flatten\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_nested\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/tree/tree_api.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dmtree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use Keras, you need to have `optree` installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall it via `pip install optree`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_tree_node_class\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree_impl\u001b[38;5;241m.\u001b[39mregister_tree_node_class(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: To use Keras, you need to have `optree` installed. Install it via `pip install optree`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import optuna\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"NLP_Dataset1.csv\")\n",
    "\n",
    "# Sample the data for quick processing\n",
    "df_sample = df.sample(n=100000, random_state=42)\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = [\n",
    "    'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "    'ActivatedTimestamp', 'ClearedTimestamp', 'month', 'week', 'ResolutionTimeMinutes'\n",
    "]\n",
    "df_selected = df_sample[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numerical using Label Encoding\n",
    "label_encoders = {}\n",
    "for column in ['organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity']:\n",
    "    le = LabelEncoder()\n",
    "    df_selected[column] = le.fit_transform(df_selected[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Convert timestamps to datetime and extract features\n",
    "df_selected['ActivatedTimestamp'] = pd.to_datetime(df_selected['ActivatedTimestamp'])\n",
    "df_selected['ClearedTimestamp'] = pd.to_datetime(df_selected['ClearedTimestamp'])\n",
    "df_selected['ActivationHour'] = df_selected['ActivatedTimestamp'].dt.hour\n",
    "df_selected['ClearanceHour'] = df_selected['ClearedTimestamp'].dt.hour\n",
    "df_selected['ActivationDayOfWeek'] = df_selected['ActivatedTimestamp'].dt.dayofweek\n",
    "df_selected['ClearanceDayOfWeek'] = df_selected['ClearedTimestamp'].dt.dayofweek\n",
    "df_selected['ResolutionTime'] = (df_selected['ClearedTimestamp'] - df_selected['ActivatedTimestamp']).dt.total_seconds() / 60\n",
    "\n",
    "# Remove rows with invalid resolution times\n",
    "df_selected = df_selected[(df_selected['ResolutionTime'] >= 0) & (df_selected['ResolutionTime'] <= 10000)]\n",
    "\n",
    "# Remove outliers\n",
    "z_scores = np.abs(stats.zscore(df_selected['ResolutionTimeMinutes']))\n",
    "df_selected = df_selected[z_scores < 3]\n",
    "\n",
    "# Normalize the ResolutionTimeMinutes column\n",
    "scaler = MinMaxScaler()\n",
    "df_selected['ResolutionTimeMinutes'] = scaler.fit_transform(df_selected[['ResolutionTimeMinutes']])\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "    'month', 'week', 'ActivationHour', 'ClearanceHour',\n",
    "    'ActivationDayOfWeek', 'ClearanceDayOfWeek'\n",
    "]\n",
    "X = df_selected[features]\n",
    "y = df_selected['ResolutionTimeMinutes']\n",
    "\n",
    "# Scale the features\n",
    "feature_scaler = StandardScaler()\n",
    "X = feature_scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature importance using Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_importances = rf.feature_importances_\n",
    "\n",
    "# Mutual Information for feature importance\n",
    "mi = mutual_info_regression(X_train, y_train)\n",
    "mi_importances = mi\n",
    "\n",
    "# Plot feature importances\n",
    "feature_names = ['organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "                 'month', 'week', 'ActivationHour', 'ClearanceHour',\n",
    "                 'ActivationDayOfWeek', 'ClearanceDayOfWeek']\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "axs[0].barh(feature_names, rf_importances)\n",
    "axs[0].set_title('Random Forest Feature Importance')\n",
    "\n",
    "# Mutual Information Feature Importance\n",
    "axs[1].barh(feature_names, mi_importances)\n",
    "axs[1].set_title('Mutual Information Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Define the hyperparameter search space\n",
    "        hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(100,), (100, 50), (150, 75), (200, 100)])\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "        solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "        alpha = trial.suggest_float('alpha', 1e-5, 1e-1, log=True)\n",
    "        learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'adaptive'])\n",
    "        max_iter = trial.suggest_int('max_iter', 300, 500)\n",
    "        \n",
    "        # Create the model\n",
    "        model = Sequential()\n",
    "        for units in hidden_layer_sizes:\n",
    "            model.add(Dense(units=units, activation=activation))\n",
    "        model.add(Dense(1))  # Output layer\n",
    "        \n",
    "        # Compile the model\n",
    "        if solver == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        \n",
    "        # Train the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        model.fit(X_train, y_train, epochs=max_iter, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        return mse\n",
    "    except Exception as e:\n",
    "        print(f\"Error during trial: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Run the optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50, timeout=600)  # Added timeout for safety\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final model using the best hyperparameters\n",
    "model = Sequential()\n",
    "for units in best_params['hidden_layer_sizes']:\n",
    "    model.add(Dense(units=units, activation=best_params['activation']))\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "if best_params['solver'] == 'adam':\n",
    "    optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
    "else:\n",
    "    optimizer = SGD(learning_rate=best_params['learning_rate'])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Train the final model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=best_params['max_iter'], batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "nn_pred_test = model.predict(X_test)\n",
    "nn_mse_test = mean_squared_error(y_test, nn_pred_test)\n",
    "nn_r2_test = r2_score(y_test, nn_pred_test)\n",
    "\n",
    "print(f\"Neural Network - Test MSE: {nn_mse_test}, R²: {nn_r2_test}\")\n",
    "\n",
    "# Convert predicted values back to original scale\n",
    "nn_pred_test_original = scaler.inverse_transform(nn_pred_test)\n",
    "\n",
    "# Display a few predicted values\n",
    "print(f\"Original Scale Predictions - Neural Network: {nn_pred_test_original[:5].ravel()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7c6c7b-3bd2-4342-af24-2d7425da62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: optree\n",
      "Version: 0.11.0\n",
      "Summary: Optimized PyTree Utilities.\n",
      "Home-page: \n",
      "Author: OpTree Contributors\n",
      "Author-email: Xuehai Pan <XuehaiPan@pku.edu.cn>, Jie Ren <jieren9806@gmail.com>\n",
      "License: Apache License, Version 2.0\n",
      "Location: /home/patil.anjali/.local/lib/python3.9/site-packages\n",
      "Requires: typing-extensions\n",
      "Required-by: keras\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show optree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d65963-4ce8-4023-b1b3-0e16ac0d5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp39-cp39-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 779.1 MB 2.1 kB/s  eta 0:00:01     |███████▍                        | 179.3 MB 22.0 MB/s eta 0:00:28     |████████                        | 194.3 MB 21.2 MB/s eta 0:00:28     |████████▏                       | 197.7 MB 21.2 MB/s eta 0:00:28     |████████▎                       | 201.5 MB 21.2 MB/s eta 0:00:28     |█████████                       | 221.2 MB 11.6 MB/s eta 0:00:48     |█████████▊                      | 236.3 MB 10.4 MB/s eta 0:00:53     |███████████                     | 270.2 MB 10.8 MB/s eta 0:00:48     |█████████████████▋              | 427.8 MB 11.5 MB/s eta 0:00:31     |██████████████████              | 437.5 MB 6.9 MB/s eta 0:00:50     |███████████████████             | 462.8 MB 7.0 MB/s eta 0:00:46     |████████████████████▏           | 491.5 MB 11.7 MB/s eta 0:00:25     |████████████████████████████▉   | 702.0 MB 9.9 MB/s eta 0:00:08     |█████████████████████████████   | 704.1 MB 9.9 MB/s eta 0:00:08     |█████████████████████████████▌  | 719.2 MB 10.3 MB/s eta 0:00:06     |██████████████████████████████▏ | 733.3 MB 11.2 MB/s eta 0:00:05     |██████████████████████████████▊ | 747.7 MB 9.5 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 24.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: optuna in ./.local/lib/python3.9/site-packages (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 11 kB/s s eta 0:00:01     |███████████▍                    | 146.2 MB 6.9 MB/s eta 0:00:39     |████████████▍                   | 158.8 MB 4.0 MB/s eta 0:01:04     |██████████████████▎             | 234.6 MB 10.7 MB/s eta 0:00:17     |███████████████████▌            | 250.2 MB 13.8 MB/s eta 0:00:12     |████████████████████▉           | 267.4 MB 12.0 MB/s eta 0:00:12     |████████████████████████████    | 358.1 MB 15.4 MB/s eta 0:00:04     |███████████████████████████████▌| 404.7 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (2.7.1)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 19.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 17.1 MB/s eta 0:00:01    |███████████████▋                | 60.4 MB 13.2 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 12.0 MB/s eta 0:00:01    |███████▏                        | 43.6 MB 16.8 MB/s eta 0:00:10     |█████████████                   | 80.1 MB 15.1 MB/s eta 0:00:08     |██████████████▉                 | 91.1 MB 7.5 MB/s eta 0:00:15     |███████████████████▌            | 119.6 MB 15.4 MB/s eta 0:00:05     |█████████████████████████████   | 177.3 MB 20.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sympy in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 11.8 MB/s eta 0:00:01     |██████▎                         | 11.1 MB 16.4 MB/s eta 0:00:03     |████████████▏                   | 21.4 MB 5.4 MB/s eta 0:00:07     |█████████████████████▎          | 37.5 MB 6.0 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 176.2 MB 11.1 MB/s eta 0:00:01     |██████████████████████▎         | 122.8 MB 3.7 MB/s eta 0:00:15\n",
      "\u001b[?25hCollecting triton==2.3.1\n",
      "  Downloading triton-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 168.1 MB 51 kB/s  eta 0:00:011    |████████▍                       | 43.8 MB 9.4 MB/s eta 0:00:14\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 731.7 MB 30 kB/s  eta 0:00:013    |█▉                              | 41.0 MB 6.1 MB/s eta 0:01:55     |███                             | 66.9 MB 15.6 MB/s eta 0:00:43     |█████                           | 112.8 MB 11.9 MB/s eta 0:00:52     |█████▏                          | 117.6 MB 13.3 MB/s eta 0:00:47     |████████▍                       | 192.0 MB 11.2 MB/s eta 0:00:49     |█████████                       | 207.2 MB 10.2 MB/s eta 0:00:52     |███████████▍                    | 261.2 MB 3.8 MB/s eta 0:02:04     |████████████▋                   | 288.4 MB 6.7 MB/s eta 0:01:07     |█████████████                   | 295.5 MB 11.8 MB/s eta 0:00:37     |█████████████▋                  | 311.6 MB 13.1 MB/s eta 0:00:33     |██████████████▊                 | 337.6 MB 11.1 MB/s eta 0:00:36     |██████████████████▋             | 425.5 MB 7.1 MB/s eta 0:00:44     |███████████████████             | 434.4 MB 8.3 MB/s eta 0:00:36     |███████████████████████         | 525.3 MB 13.1 MB/s eta 0:00:16     |████████████████████████▏       | 551.5 MB 8.8 MB/s eta 0:00:21     |████████████████████████▊       | 565.6 MB 11.0 MB/s eta 0:00:16     |█████████████████████████       | 572.1 MB 12.0 MB/s eta 0:00:14     |██████████████████████████      | 596.0 MB 12.6 MB/s eta 0:00:11\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 6.4 MB/s eta 0:00:01     |████████████████████████████▉   | 12.7 MB 6.4 MB/s eta 0:00:01     |████████████████████████████████| 14.1 MB 6.4 MB/s \n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 1.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (2022.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.3 MB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./.local/lib/python3.9/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: PyYAML in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: colorlog in ./.local/lib/python3.9/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: tqdm in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.local/lib/python3.9/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: Mako in ./.local/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, typing-extensions, triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, torch, torchvision\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-2.3.1 torchvision-0.18.1 triton-2.3.1 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656f70aa-7249-4b29-be4e-00cb6e8b2fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: jinja2 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: sympy in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.local/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.local/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.3.1 in ./.local/lib/python3.9/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: fsspec in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b679b10a-1104-43f1-8a57-4eb1c30e296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7748/59350845.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/59350845.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/59350845.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/59350845.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/59350845.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ActivatedTimestamp'] = pd.to_datetime(df_selected['ActivatedTimestamp'])\n",
      "/tmp/ipykernel_7748/59350845.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ClearedTimestamp'] = pd.to_datetime(df_selected['ClearedTimestamp'])\n",
      "/tmp/ipykernel_7748/59350845.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ActivationHour'] = df_selected['ActivatedTimestamp'].dt.hour\n",
      "/tmp/ipykernel_7748/59350845.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ClearanceHour'] = df_selected['ClearedTimestamp'].dt.hour\n",
      "/tmp/ipykernel_7748/59350845.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ActivationDayOfWeek'] = df_selected['ActivatedTimestamp'].dt.dayofweek\n",
      "/tmp/ipykernel_7748/59350845.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ClearanceDayOfWeek'] = df_selected['ClearedTimestamp'].dt.dayofweek\n",
      "/tmp/ipykernel_7748/59350845.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ResolutionTime'] = (df_selected['ClearedTimestamp'] - df_selected['ActivatedTimestamp']).dt.total_seconds() / 60\n",
      "[I 2024-06-23 15:00:56,844] A new study created in memory with name: no-name-4e7fd9fd-ecf4-4062-bf7a-317ababfb525\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (150, 75) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (200, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2024-06-23 15:03:35,067] Trial 0 finished with value: 0.001010310214508801 and parameters: {'hidden_layers': (150, 75), 'activation': 'relu', 'solver': 'adam', 'lr': 0.007347098171594648, 'n_epochs': 75}. Best is trial 0 with value: 0.001010310214508801.\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (150, 75) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (200, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2024-06-23 15:05:54,994] Trial 1 finished with value: 8.602180031723857e-05 and parameters: {'hidden_layers': (100, 50), 'activation': 'tanh', 'solver': 'adam', 'lr': 2.391384032370337e-05, 'n_epochs': 68}. Best is trial 1 with value: 8.602180031723857e-05.\n",
      "[I 2024-06-23 15:09:20,542] Trial 2 finished with value: 7.299224935862084e-05 and parameters: {'hidden_layers': (200, 100), 'activation': 'tanh', 'solver': 'adam', 'lr': 4.396022277642128e-05, 'n_epochs': 99}. Best is trial 2 with value: 7.299224935862084e-05.\n",
      "[I 2024-06-23 15:12:17,483] Trial 3 finished with value: 0.00455577077304581 and parameters: {'hidden_layers': (150, 75), 'activation': 'tanh', 'solver': 'sgd', 'lr': 3.653766970064786e-05, 'n_epochs': 99}. Best is trial 2 with value: 7.299224935862084e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_layers': (200, 100), 'activation': 'tanh', 'solver': 'adam', 'lr': 4.396022277642128e-05, 'n_epochs': 99}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 195>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m test_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Calculate test R²\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m y_test_true \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    197\u001b[0m test_r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test_true, y_test_pred)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import optuna\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'tableau_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Sample the data for quick processing\n",
    "df_sample = df.sample(n=100000, random_state=42)\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = [\n",
    "    'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "    'ActivatedTimestamp', 'ClearedTimestamp', 'month', 'week', 'ResolutionTimeMinutes'\n",
    "]\n",
    "df_selected = df_sample[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numerical using Label Encoding\n",
    "label_encoders = {}\n",
    "for column in ['organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity']:\n",
    "    le = LabelEncoder()\n",
    "    df_selected[column] = le.fit_transform(df_selected[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Convert timestamps to datetime and extract features\n",
    "df_selected['ActivatedTimestamp'] = pd.to_datetime(df_selected['ActivatedTimestamp'])\n",
    "df_selected['ClearedTimestamp'] = pd.to_datetime(df_selected['ClearedTimestamp'])\n",
    "df_selected['ActivationHour'] = df_selected['ActivatedTimestamp'].dt.hour\n",
    "df_selected['ClearanceHour'] = df_selected['ClearedTimestamp'].dt.hour\n",
    "df_selected['ActivationDayOfWeek'] = df_selected['ActivatedTimestamp'].dt.dayofweek\n",
    "df_selected['ClearanceDayOfWeek'] = df_selected['ClearedTimestamp'].dt.dayofweek\n",
    "df_selected['ResolutionTime'] = (df_selected['ClearedTimestamp'] - df_selected['ActivatedTimestamp']).dt.total_seconds() / 60\n",
    "\n",
    "# Remove rows with invalid resolution times\n",
    "df_selected = df_selected[(df_selected['ResolutionTime'] >= 0) & (df_selected['ResolutionTime'] <= 10000)]\n",
    "\n",
    "# Remove outliers\n",
    "z_scores = np.abs(stats.zscore(df_selected['ResolutionTimeMinutes']))\n",
    "df_selected = df_selected[z_scores < 3]\n",
    "\n",
    "# Normalize the ResolutionTimeMinutes column\n",
    "scaler = MinMaxScaler()\n",
    "df_selected['ResolutionTimeMinutes'] = scaler.fit_transform(df_selected[['ResolutionTimeMinutes']])\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "    'month', 'week', 'ActivationHour', 'ClearanceHour',\n",
    "    'ActivationDayOfWeek', 'ClearanceDayOfWeek'\n",
    "]\n",
    "X = df_selected[features]\n",
    "y = df_selected['ResolutionTimeMinutes']\n",
    "\n",
    "# Scale the features\n",
    "feature_scaler = StandardScaler()\n",
    "X = feature_scaler.fit_transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device).view(-1, 1)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the PyTorch neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, activation):\n",
    "        super(Net, self).__init__()\n",
    "        layers = []\n",
    "        for units in hidden_layers:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            if activation == 'relu':\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == 'tanh':\n",
    "                layers.append(nn.Tanh())\n",
    "            input_dim = units\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Define the hyperparameter search space\n",
    "        hidden_layers = trial.suggest_categorical('hidden_layers', [(100,), (100, 50), (150, 75), (200, 100)])\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "        solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "        lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "        n_epochs = trial.suggest_int('n_epochs', 50, 100)\n",
    "\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        model = Net(X_train.shape[1], hidden_layers, activation).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        if solver == 'adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(n_epochs):\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        return val_loss\n",
    "    except Exception as e:\n",
    "        print(f\"Error during trial: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Run the optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50, timeout=600)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final model using the best hyperparameters\n",
    "best_hidden_layers = best_params['hidden_layers']\n",
    "best_activation = best_params['activation']\n",
    "best_solver = best_params['solver']\n",
    "best_lr = best_params['lr']\n",
    "best_n_epochs = best_params['n_epochs']\n",
    "\n",
    "model = Net(X_train.shape[1], best_hidden_layers, best_activation).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "if best_solver == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_lr)\n",
    "\n",
    "# Training loop for the final model\n",
    "model.train()\n",
    "for epoch in range(best_n_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item() * X_batch.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "# # Calculate test R²\n",
    "# y_test_pred = model(X_test).cpu().numpy()\n",
    "# y_test_true = y_test.cpu().numpy()\n",
    "# test_r2 = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "# print(f\"Neural Network - Test MSE: {test_loss}, R²: {test_r2}\")\n",
    "\n",
    "# # Convert predicted values back to original scale\n",
    "# nn_pred_test_original = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Display a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ae235b-cc36-4e7c-b1e7-8cbc0ad2210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Test MSE: 7.310122509195074e-05, R²: 0.9837267398834229\n",
      "Original Scale Predictions - Neural Network: [-0.21367742  2.1354895   2.0554235  63.624157   -2.490572  ]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model(X_test).detach().cpu().numpy()\n",
    "y_test_true = y_test.detach().cpu().numpy()\n",
    "test_r2 = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "print(f\"Neural Network - Test MSE: {test_loss}, R²: {test_r2}\")\n",
    "\n",
    "# Convert predicted values back to original scale\n",
    "nn_pred_test_original = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Display a few predicted values\n",
    "print(f\"Original Scale Predictions - Neural Network: {nn_pred_test_original[:5].ravel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e8ffc2-3b14-42e0-bab4-d0f271e0e4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Test MSE: 7.310122509195074e-05, R²: 0.9839843511581421\n",
      "Original Scale Predictions - Neural Network: [ 0.         2.1354895  2.0554235 63.624157   0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate test R²\n",
    "y_test_pred = model(X_test).detach().cpu().numpy()\n",
    "y_test_true = y_test.detach().cpu().numpy()\n",
    "\n",
    "# Ensure no negative predictions\n",
    "y_test_pred = np.maximum(y_test_pred, 0)\n",
    "\n",
    "test_r2 = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "print(f\"Neural Network - Test MSE: {test_loss}, R²: {test_r2}\")\n",
    "\n",
    "# Convert predicted values back to original scale\n",
    "nn_pred_test_original = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Ensure no negative values after inverse transform\n",
    "nn_pred_test_original = np.maximum(nn_pred_test_original, 0)\n",
    "\n",
    "# Display a few predicted values\n",
    "print(f\"Original Scale Predictions - Neural Network: {nn_pred_test_original[:5].ravel()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2f61bd8-af9c-44eb-960f-45a14ba4d64b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         random_state \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Find the test row\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m test_row \u001b[38;5;241m=\u001b[39m \u001b[43mfind_test_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Print the selected test row\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest row found:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mfind_test_row\u001b[0;34m(df_main, df_sample)\u001b[0m\n\u001b[1;32m      2\u001b[0m random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     test_row \u001b[38;5;241m=\u001b[39m \u001b[43mdf_main\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m test_row\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(df_sample\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m test_row\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py:6119\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6116\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m   6118\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39msample(obj_len, size, replace, weights, rs)\n\u001b[0;32m-> 6119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   6122\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py:893\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m--> 893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    895\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[1;32m    896\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    900\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/indexes/range.py:1173\u001b[0m, in \u001b[0;36mRangeIndex.take\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ind_max \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mind_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for axis 0 with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1172\u001b[0m     )\n\u001b[0;32m-> 1173\u001b[0m ind_min \u001b[38;5;241m=\u001b[39m \u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ind_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mind_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for axis 0 with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1177\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/core/_methods.py:42\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def find_test_row(df_main, df_sample):\n",
    "    random_state = 0\n",
    "    while True:\n",
    "        test_row = df_main.sample(n=1, random_state=random_state)\n",
    "        if not test_row.index.isin(df_sample.index).any():\n",
    "            return test_row\n",
    "        random_state += 1\n",
    "\n",
    "# Find the test row\n",
    "test_row = find_test_row(df, df_sample)\n",
    "\n",
    "# Print the selected test row\n",
    "print(\"Test row found:\")\n",
    "print(test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb2fdec8-97cb-4e45-a2a9-06546f4b5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows with ResolutionTimeMinutes between 2 and 2.9\n",
    "filtered_df = df[(df['ResolutionTimeMinutes'] >= 1.6) & (df['ResolutionTimeMinutes'] <= 1.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85aa6b79-1eea-47d7-bb9f-6e34e53b2a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssetId</th>\n",
       "      <th>organizationid</th>\n",
       "      <th>organizationcountrycode</th>\n",
       "      <th>locationid</th>\n",
       "      <th>AssetType</th>\n",
       "      <th>AlarmLabel</th>\n",
       "      <th>AlarmMessage</th>\n",
       "      <th>Severity</th>\n",
       "      <th>ActivatedTimestamp</th>\n",
       "      <th>ClearedTimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>ResolutionTimeMinutes</th>\n",
       "      <th>Lemmas_No_Stop_Words</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>organizationid_code</th>\n",
       "      <th>organizationcountrycode_code</th>\n",
       "      <th>locationid_code</th>\n",
       "      <th>AssetType_code</th>\n",
       "      <th>AlarmLabel_code</th>\n",
       "      <th>AlarmMessage_code</th>\n",
       "      <th>Severity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37571</th>\n",
       "      <td>9339ab57-075b-401b-9519-382ec1f5c9dc</td>\n",
       "      <td>59062bc2-16ca-4b9d-b6e7-2720ebfd802e</td>\n",
       "      <td>GB</td>\n",
       "      <td>ebc0d7c9-9250-4950-b17f-64e5769a5e00</td>\n",
       "      <td>RPDU</td>\n",
       "      <td>High Temperature Threshold Violation</td>\n",
       "      <td>Rack PDU 1: High temperature threshold violati...</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-05-06T16:34:04Z</td>\n",
       "      <td>2021-05-06T16:35:52Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>['high', 'temperature', 'threshold', 'violation']</td>\n",
       "      <td>['high', 'temperature', 'threshold', 'violation']</td>\n",
       "      <td>1168</td>\n",
       "      <td>34</td>\n",
       "      <td>9498</td>\n",
       "      <td>28</td>\n",
       "      <td>4601</td>\n",
       "      <td>23978</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22830</th>\n",
       "      <td>0884b460-6ae1-497d-ac75-01d81ae54bdc</td>\n",
       "      <td>a6e2c146-021d-4036-9973-de0c1975692d</td>\n",
       "      <td>US</td>\n",
       "      <td>2f32a9eb-dd5b-4355-9f0e-82f861bba81f</td>\n",
       "      <td>POD</td>\n",
       "      <td>NetBotz Appliance Alarm</td>\n",
       "      <td>The value of 'redact' was too high; but has no...</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>2021-06-15T02:18:55Z</td>\n",
       "      <td>2021-06-15T02:20:36Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.683333</td>\n",
       "      <td>['netbotz', 'appliance', 'alarm']</td>\n",
       "      <td>['netbotz', 'appliance', 'alarm']</td>\n",
       "      <td>2176</td>\n",
       "      <td>93</td>\n",
       "      <td>1918</td>\n",
       "      <td>23</td>\n",
       "      <td>6513</td>\n",
       "      <td>39171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52764</th>\n",
       "      <td>04d82354-9794-4da1-a8c0-03e6d1be4013</td>\n",
       "      <td>f86de2dc-3bde-429a-94af-0f0850e10cca</td>\n",
       "      <td>US</td>\n",
       "      <td>0eb42999-2fcc-46f4-9a75-c0ad2eb9e012</td>\n",
       "      <td>ATS</td>\n",
       "      <td>Source Status Fault</td>\n",
       "      <td>Source A is unavailable or a status problem ex...</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-03-13T23:43:53Z</td>\n",
       "      <td>2021-03-13T23:45:41Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>['source', 'status', 'fault']</td>\n",
       "      <td>['source', 'status', 'fault']</td>\n",
       "      <td>3181</td>\n",
       "      <td>93</td>\n",
       "      <td>606</td>\n",
       "      <td>3</td>\n",
       "      <td>8150</td>\n",
       "      <td>27669</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55801</th>\n",
       "      <td>289b3e86-2107-4ab7-a2b1-d173f3868866</td>\n",
       "      <td>36cafccc-187a-445b-b601-d46eb06bf19f</td>\n",
       "      <td>FR</td>\n",
       "      <td>eaa13df7-5840-40c4-bf57-5cae36f7cd37</td>\n",
       "      <td>RPDU</td>\n",
       "      <td>Phase Near Overload Cleared</td>\n",
       "      <td>Rack PDU 1: A near overload threshold violatio...</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-05-22T07:52:48Z</td>\n",
       "      <td>2021-05-22T07:54:26Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>['phase', 'near', 'overload', 'clear']</td>\n",
       "      <td>['phase', 'near', 'overload', 'cleared']</td>\n",
       "      <td>708</td>\n",
       "      <td>33</td>\n",
       "      <td>9455</td>\n",
       "      <td>28</td>\n",
       "      <td>6969</td>\n",
       "      <td>23437</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84601</th>\n",
       "      <td>f1daed81-c618-4bc2-88c5-8017773596b4</td>\n",
       "      <td>4bea371d-7048-490a-a933-fdf63e8f9ade</td>\n",
       "      <td>US</td>\n",
       "      <td>86c03d1c-85f0-4824-af4d-a1db1f439530</td>\n",
       "      <td>RPDU</td>\n",
       "      <td>Low Humidity Threshold Violation Cleared</td>\n",
       "      <td>Rack PDU 1: Low humidity threshold violation c...</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-03-16T03:53:37Z</td>\n",
       "      <td>2021-03-16T03:55:13Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>['low', 'humidity', 'threshold', 'violation', ...</td>\n",
       "      <td>['low', 'humidity', 'threshold', 'violation', ...</td>\n",
       "      <td>997</td>\n",
       "      <td>93</td>\n",
       "      <td>5531</td>\n",
       "      <td>28</td>\n",
       "      <td>5856</td>\n",
       "      <td>24335</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72269</th>\n",
       "      <td>27ae3ac2-475f-4973-8f82-c963dd4f7c7f</td>\n",
       "      <td>4a2c4e98-ab37-4e5f-92e8-3a956d1794f9</td>\n",
       "      <td>RO</td>\n",
       "      <td>Default Location</td>\n",
       "      <td>RPDU</td>\n",
       "      <td>CAN Bus Off</td>\n",
       "      <td>Rack PDU 1: CAN bus on</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-06-14T18:35:06Z</td>\n",
       "      <td>2021-06-14T18:36:55Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.816667</td>\n",
       "      <td>['bus']</td>\n",
       "      <td>['can', 'bus', 'off']</td>\n",
       "      <td>962</td>\n",
       "      <td>79</td>\n",
       "      <td>6517</td>\n",
       "      <td>28</td>\n",
       "      <td>1917</td>\n",
       "      <td>23470</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20795</th>\n",
       "      <td>56899c85-a973-4b22-a367-0a2c3174cff7</td>\n",
       "      <td>b089f434-eb43-4d8d-a86d-a40e3279414a</td>\n",
       "      <td>US</td>\n",
       "      <td>cc570913-ba14-4ea6-9012-9fd788944312</td>\n",
       "      <td>POD</td>\n",
       "      <td>NetBotz Appliance Alarm</td>\n",
       "      <td>The value of 'redact' was too low; but has now...</td>\n",
       "      <td>INFO</td>\n",
       "      <td>2021-03-11T03:07:15Z</td>\n",
       "      <td>2021-03-11T03:09:05Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>['netbotz', 'appliance', 'alarm']</td>\n",
       "      <td>['netbotz', 'appliance', 'alarm']</td>\n",
       "      <td>2309</td>\n",
       "      <td>93</td>\n",
       "      <td>8275</td>\n",
       "      <td>23</td>\n",
       "      <td>6513</td>\n",
       "      <td>39173</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66355</th>\n",
       "      <td>d648f7bb-8625-449f-bad3-21cfd161f79f</td>\n",
       "      <td>fe89c15f-eb13-45ad-8a8f-2fa7b238a71b</td>\n",
       "      <td>US</td>\n",
       "      <td>Default Location</td>\n",
       "      <td>RPDU</td>\n",
       "      <td>Phase Near Overload</td>\n",
       "      <td>Rack PDU 1: A near overload threshold violatio...</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-04-23T11:55:04Z</td>\n",
       "      <td>2021-04-23T11:56:54Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>['phase', 'near', 'overload']</td>\n",
       "      <td>['phase', 'near', 'overload']</td>\n",
       "      <td>3262</td>\n",
       "      <td>93</td>\n",
       "      <td>6517</td>\n",
       "      <td>28</td>\n",
       "      <td>6968</td>\n",
       "      <td>23428</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89595</th>\n",
       "      <td>c9ac5b92-4e4c-411c-ac81-316d8daae9cc</td>\n",
       "      <td>36cafccc-187a-445b-b601-d46eb06bf19f</td>\n",
       "      <td>FR</td>\n",
       "      <td>cac4ce42-5f3e-4e8e-9b18-2e8d9fd2811c</td>\n",
       "      <td>RPDU</td>\n",
       "      <td>Bank Overload Cleared</td>\n",
       "      <td>Rack PDU 1: An overload threshold violation no...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>2021-02-27T04:25:02Z</td>\n",
       "      <td>2021-02-27T04:26:41Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>['bank', 'overload', 'clear']</td>\n",
       "      <td>['bank', 'overload', 'cleared']</td>\n",
       "      <td>708</td>\n",
       "      <td>33</td>\n",
       "      <td>8207</td>\n",
       "      <td>28</td>\n",
       "      <td>921</td>\n",
       "      <td>23460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37060</th>\n",
       "      <td>af2e544d-6aab-4790-9155-01abd9b29972</td>\n",
       "      <td>52763390-98b2-4fb8-9ffb-dc35c8147582</td>\n",
       "      <td>US</td>\n",
       "      <td>2fc3aee0-4771-417c-8a5a-115d3cc737a8</td>\n",
       "      <td>PDU</td>\n",
       "      <td>High Module Current Alarm</td>\n",
       "      <td>Distribution module 5 breaker L2 current is ab...</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-06-14T19:35:13Z</td>\n",
       "      <td>2021-06-14T19:37:06Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>['high', 'module', 'current', 'alarm']</td>\n",
       "      <td>['high', 'module', 'current', 'alarm']</td>\n",
       "      <td>1076</td>\n",
       "      <td>93</td>\n",
       "      <td>1936</td>\n",
       "      <td>22</td>\n",
       "      <td>4547</td>\n",
       "      <td>5693</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    AssetId  \\\n",
       "37571  9339ab57-075b-401b-9519-382ec1f5c9dc   \n",
       "22830  0884b460-6ae1-497d-ac75-01d81ae54bdc   \n",
       "52764  04d82354-9794-4da1-a8c0-03e6d1be4013   \n",
       "55801  289b3e86-2107-4ab7-a2b1-d173f3868866   \n",
       "84601  f1daed81-c618-4bc2-88c5-8017773596b4   \n",
       "72269  27ae3ac2-475f-4973-8f82-c963dd4f7c7f   \n",
       "20795  56899c85-a973-4b22-a367-0a2c3174cff7   \n",
       "66355  d648f7bb-8625-449f-bad3-21cfd161f79f   \n",
       "89595  c9ac5b92-4e4c-411c-ac81-316d8daae9cc   \n",
       "37060  af2e544d-6aab-4790-9155-01abd9b29972   \n",
       "\n",
       "                             organizationid organizationcountrycode  \\\n",
       "37571  59062bc2-16ca-4b9d-b6e7-2720ebfd802e                      GB   \n",
       "22830  a6e2c146-021d-4036-9973-de0c1975692d                      US   \n",
       "52764  f86de2dc-3bde-429a-94af-0f0850e10cca                      US   \n",
       "55801  36cafccc-187a-445b-b601-d46eb06bf19f                      FR   \n",
       "84601  4bea371d-7048-490a-a933-fdf63e8f9ade                      US   \n",
       "72269  4a2c4e98-ab37-4e5f-92e8-3a956d1794f9                      RO   \n",
       "20795  b089f434-eb43-4d8d-a86d-a40e3279414a                      US   \n",
       "66355  fe89c15f-eb13-45ad-8a8f-2fa7b238a71b                      US   \n",
       "89595  36cafccc-187a-445b-b601-d46eb06bf19f                      FR   \n",
       "37060  52763390-98b2-4fb8-9ffb-dc35c8147582                      US   \n",
       "\n",
       "                                 locationid AssetType  \\\n",
       "37571  ebc0d7c9-9250-4950-b17f-64e5769a5e00      RPDU   \n",
       "22830  2f32a9eb-dd5b-4355-9f0e-82f861bba81f       POD   \n",
       "52764  0eb42999-2fcc-46f4-9a75-c0ad2eb9e012       ATS   \n",
       "55801  eaa13df7-5840-40c4-bf57-5cae36f7cd37      RPDU   \n",
       "84601  86c03d1c-85f0-4824-af4d-a1db1f439530      RPDU   \n",
       "72269                      Default Location      RPDU   \n",
       "20795  cc570913-ba14-4ea6-9012-9fd788944312       POD   \n",
       "66355                      Default Location      RPDU   \n",
       "89595  cac4ce42-5f3e-4e8e-9b18-2e8d9fd2811c      RPDU   \n",
       "37060  2fc3aee0-4771-417c-8a5a-115d3cc737a8       PDU   \n",
       "\n",
       "                                     AlarmLabel  \\\n",
       "37571      High Temperature Threshold Violation   \n",
       "22830                   NetBotz Appliance Alarm   \n",
       "52764                       Source Status Fault   \n",
       "55801               Phase Near Overload Cleared   \n",
       "84601  Low Humidity Threshold Violation Cleared   \n",
       "72269                               CAN Bus Off   \n",
       "20795                   NetBotz Appliance Alarm   \n",
       "66355                       Phase Near Overload   \n",
       "89595                     Bank Overload Cleared   \n",
       "37060                 High Module Current Alarm   \n",
       "\n",
       "                                            AlarmMessage  Severity  \\\n",
       "37571  Rack PDU 1: High temperature threshold violati...   WARNING   \n",
       "22830  The value of 'redact' was too high; but has no...     ERROR   \n",
       "52764  Source A is unavailable or a status problem ex...   WARNING   \n",
       "55801  Rack PDU 1: A near overload threshold violatio...   WARNING   \n",
       "84601  Rack PDU 1: Low humidity threshold violation c...   WARNING   \n",
       "72269                             Rack PDU 1: CAN bus on   WARNING   \n",
       "20795  The value of 'redact' was too low; but has now...      INFO   \n",
       "66355  Rack PDU 1: A near overload threshold violatio...   WARNING   \n",
       "89595  Rack PDU 1: An overload threshold violation no...  CRITICAL   \n",
       "37060  Distribution module 5 breaker L2 current is ab...   WARNING   \n",
       "\n",
       "         ActivatedTimestamp      ClearedTimestamp  ...  ResolutionTimeMinutes  \\\n",
       "37571  2021-05-06T16:34:04Z  2021-05-06T16:35:52Z  ...               1.800000   \n",
       "22830  2021-06-15T02:18:55Z  2021-06-15T02:20:36Z  ...               1.683333   \n",
       "52764  2021-03-13T23:43:53Z  2021-03-13T23:45:41Z  ...               1.800000   \n",
       "55801  2021-05-22T07:52:48Z  2021-05-22T07:54:26Z  ...               1.633333   \n",
       "84601  2021-03-16T03:53:37Z  2021-03-16T03:55:13Z  ...               1.600000   \n",
       "72269  2021-06-14T18:35:06Z  2021-06-14T18:36:55Z  ...               1.816667   \n",
       "20795  2021-03-11T03:07:15Z  2021-03-11T03:09:05Z  ...               1.833333   \n",
       "66355  2021-04-23T11:55:04Z  2021-04-23T11:56:54Z  ...               1.833333   \n",
       "89595  2021-02-27T04:25:02Z  2021-02-27T04:26:41Z  ...               1.650000   \n",
       "37060  2021-06-14T19:35:13Z  2021-06-14T19:37:06Z  ...               1.883333   \n",
       "\n",
       "                                    Lemmas_No_Stop_Words  \\\n",
       "37571  ['high', 'temperature', 'threshold', 'violation']   \n",
       "22830                  ['netbotz', 'appliance', 'alarm']   \n",
       "52764                      ['source', 'status', 'fault']   \n",
       "55801             ['phase', 'near', 'overload', 'clear']   \n",
       "84601  ['low', 'humidity', 'threshold', 'violation', ...   \n",
       "72269                                            ['bus']   \n",
       "20795                  ['netbotz', 'appliance', 'alarm']   \n",
       "66355                      ['phase', 'near', 'overload']   \n",
       "89595                      ['bank', 'overload', 'clear']   \n",
       "37060             ['high', 'module', 'current', 'alarm']   \n",
       "\n",
       "                                                  Tokens organizationid_code  \\\n",
       "37571  ['high', 'temperature', 'threshold', 'violation']                1168   \n",
       "22830                  ['netbotz', 'appliance', 'alarm']                2176   \n",
       "52764                      ['source', 'status', 'fault']                3181   \n",
       "55801           ['phase', 'near', 'overload', 'cleared']                 708   \n",
       "84601  ['low', 'humidity', 'threshold', 'violation', ...                 997   \n",
       "72269                              ['can', 'bus', 'off']                 962   \n",
       "20795                  ['netbotz', 'appliance', 'alarm']                2309   \n",
       "66355                      ['phase', 'near', 'overload']                3262   \n",
       "89595                    ['bank', 'overload', 'cleared']                 708   \n",
       "37060             ['high', 'module', 'current', 'alarm']                1076   \n",
       "\n",
       "      organizationcountrycode_code  locationid_code  AssetType_code  \\\n",
       "37571                           34             9498              28   \n",
       "22830                           93             1918              23   \n",
       "52764                           93              606               3   \n",
       "55801                           33             9455              28   \n",
       "84601                           93             5531              28   \n",
       "72269                           79             6517              28   \n",
       "20795                           93             8275              23   \n",
       "66355                           93             6517              28   \n",
       "89595                           33             8207              28   \n",
       "37060                           93             1936              22   \n",
       "\n",
       "       AlarmLabel_code  AlarmMessage_code  Severity_code  \n",
       "37571             4601              23978              4  \n",
       "22830             6513              39171              1  \n",
       "52764             8150              27669              4  \n",
       "55801             6969              23437              4  \n",
       "84601             5856              24335              4  \n",
       "72269             1917              23470              4  \n",
       "20795             6513              39173              3  \n",
       "66355             6968              23428              4  \n",
       "89595              921              23460              0  \n",
       "37060             4547               5693              4  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = filtered_df.sample(n=10,random_state = 1224)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89df37b9-0a4b-44ce-93c3-5c91024ca94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssetId</th>\n",
       "      <th>organizationid</th>\n",
       "      <th>organizationcountrycode</th>\n",
       "      <th>locationid</th>\n",
       "      <th>AssetType</th>\n",
       "      <th>AlarmLabel</th>\n",
       "      <th>AlarmMessage</th>\n",
       "      <th>Severity</th>\n",
       "      <th>ActivatedTimestamp</th>\n",
       "      <th>ClearedTimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>ResolutionTimeMinutes</th>\n",
       "      <th>Lemmas_No_Stop_Words</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>organizationid_code</th>\n",
       "      <th>organizationcountrycode_code</th>\n",
       "      <th>locationid_code</th>\n",
       "      <th>AssetType_code</th>\n",
       "      <th>AlarmLabel_code</th>\n",
       "      <th>AlarmMessage_code</th>\n",
       "      <th>Severity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55801</th>\n",
       "      <td>289b3e86-2107-4ab7-a2b1-d173f3868866</td>\n",
       "      <td>36cafccc-187a-445b-b601-d46eb06bf19f</td>\n",
       "      <td>FR</td>\n",
       "      <td>eaa13df7-5840-40c4-bf57-5cae36f7cd37</td>\n",
       "      <td>RPDU</td>\n",
       "      <td>Phase Near Overload Cleared</td>\n",
       "      <td>Rack PDU 1: A near overload threshold violatio...</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-05-22T07:52:48Z</td>\n",
       "      <td>2021-05-22T07:54:26Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>['phase', 'near', 'overload', 'clear']</td>\n",
       "      <td>['phase', 'near', 'overload', 'cleared']</td>\n",
       "      <td>708</td>\n",
       "      <td>33</td>\n",
       "      <td>9455</td>\n",
       "      <td>28</td>\n",
       "      <td>6969</td>\n",
       "      <td>23437</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    AssetId  \\\n",
       "55801  289b3e86-2107-4ab7-a2b1-d173f3868866   \n",
       "\n",
       "                             organizationid organizationcountrycode  \\\n",
       "55801  36cafccc-187a-445b-b601-d46eb06bf19f                      FR   \n",
       "\n",
       "                                 locationid AssetType  \\\n",
       "55801  eaa13df7-5840-40c4-bf57-5cae36f7cd37      RPDU   \n",
       "\n",
       "                        AlarmLabel  \\\n",
       "55801  Phase Near Overload Cleared   \n",
       "\n",
       "                                            AlarmMessage Severity  \\\n",
       "55801  Rack PDU 1: A near overload threshold violatio...  WARNING   \n",
       "\n",
       "         ActivatedTimestamp      ClearedTimestamp  ...  ResolutionTimeMinutes  \\\n",
       "55801  2021-05-22T07:52:48Z  2021-05-22T07:54:26Z  ...               1.633333   \n",
       "\n",
       "                         Lemmas_No_Stop_Words  \\\n",
       "55801  ['phase', 'near', 'overload', 'clear']   \n",
       "\n",
       "                                         Tokens organizationid_code  \\\n",
       "55801  ['phase', 'near', 'overload', 'cleared']                 708   \n",
       "\n",
       "      organizationcountrycode_code  locationid_code  AssetType_code  \\\n",
       "55801                           33             9455              28   \n",
       "\n",
       "       AlarmLabel_code  AlarmMessage_code  Severity_code  \n",
       "55801             6969              23437              4  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row=xx.loc[[55801]]\n",
    "test_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a94b228-2d71-4010-bac9-8154c125cc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7748/1806557126.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test_row = df[\n"
     ]
    }
   ],
   "source": [
    "test_row = df[\n",
    "    (df_sample['AssetId'].astype(str) == '6255f030-8744-4d1e-b7ca-f6f3e4e4774d') &\n",
    "    (df_sample['organizationid'].astype(str) == 'c7553c18-7a3d-4728-8d19-b10267ae72e5') &\n",
    "    (df_sample['organizationcountrycode'].astype(str) == 'US') &\n",
    "    (df_sample['locationid'].astype(str) == '2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e') &\n",
    "    (df_sample['AssetType'].astype(str) == 'UPS') &\n",
    "    (df_sample['AlarmLabel'].astype(str) == 'Battery Charger Fault') &\n",
    "    (df_sample['AlarmMessage'].astype(str) == 'A battery charger error exists.') &\n",
    "    (df_sample['Severity'].astype(str) == 'WARNING') \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eac2ce66-e3d0-4b09-9868-fbfa1dce393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssetId</th>\n",
       "      <th>organizationid</th>\n",
       "      <th>organizationcountrycode</th>\n",
       "      <th>locationid</th>\n",
       "      <th>AssetType</th>\n",
       "      <th>AlarmLabel</th>\n",
       "      <th>AlarmMessage</th>\n",
       "      <th>Severity</th>\n",
       "      <th>ActivatedTimestamp</th>\n",
       "      <th>ClearedTimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>ResolutionTimeMinutes</th>\n",
       "      <th>Lemmas_No_Stop_Words</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>organizationid_code</th>\n",
       "      <th>organizationcountrycode_code</th>\n",
       "      <th>locationid_code</th>\n",
       "      <th>AssetType_code</th>\n",
       "      <th>AlarmLabel_code</th>\n",
       "      <th>AlarmMessage_code</th>\n",
       "      <th>Severity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70759</th>\n",
       "      <td>6255f030-8744-4d1e-b7ca-f6f3e4e4774d</td>\n",
       "      <td>c7553c18-7a3d-4728-8d19-b10267ae72e5</td>\n",
       "      <td>US</td>\n",
       "      <td>2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e</td>\n",
       "      <td>UPS</td>\n",
       "      <td>Battery Charger Fault</td>\n",
       "      <td>A battery charger error exists.</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-06-28T09:50:17Z</td>\n",
       "      <td>2021-06-28T09:50:50Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>2579</td>\n",
       "      <td>93</td>\n",
       "      <td>1809</td>\n",
       "      <td>33</td>\n",
       "      <td>1012</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72736</th>\n",
       "      <td>6255f030-8744-4d1e-b7ca-f6f3e4e4774d</td>\n",
       "      <td>c7553c18-7a3d-4728-8d19-b10267ae72e5</td>\n",
       "      <td>US</td>\n",
       "      <td>2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e</td>\n",
       "      <td>UPS</td>\n",
       "      <td>Battery Charger Fault</td>\n",
       "      <td>A battery charger error exists.</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-04-29T05:00:59Z</td>\n",
       "      <td>2021-04-29T05:01:31Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>2579</td>\n",
       "      <td>93</td>\n",
       "      <td>1809</td>\n",
       "      <td>33</td>\n",
       "      <td>1012</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38214</th>\n",
       "      <td>6255f030-8744-4d1e-b7ca-f6f3e4e4774d</td>\n",
       "      <td>c7553c18-7a3d-4728-8d19-b10267ae72e5</td>\n",
       "      <td>US</td>\n",
       "      <td>2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e</td>\n",
       "      <td>UPS</td>\n",
       "      <td>Battery Charger Fault</td>\n",
       "      <td>A battery charger error exists.</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-02-26T00:20:29Z</td>\n",
       "      <td>2021-02-26T00:21:01Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>2579</td>\n",
       "      <td>93</td>\n",
       "      <td>1809</td>\n",
       "      <td>33</td>\n",
       "      <td>1012</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85352</th>\n",
       "      <td>6255f030-8744-4d1e-b7ca-f6f3e4e4774d</td>\n",
       "      <td>c7553c18-7a3d-4728-8d19-b10267ae72e5</td>\n",
       "      <td>US</td>\n",
       "      <td>2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e</td>\n",
       "      <td>UPS</td>\n",
       "      <td>Battery Charger Fault</td>\n",
       "      <td>A battery charger error exists.</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-02-18T16:20:41Z</td>\n",
       "      <td>2021-02-18T16:21:13Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>2579</td>\n",
       "      <td>93</td>\n",
       "      <td>1809</td>\n",
       "      <td>33</td>\n",
       "      <td>1012</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84853</th>\n",
       "      <td>6255f030-8744-4d1e-b7ca-f6f3e4e4774d</td>\n",
       "      <td>c7553c18-7a3d-4728-8d19-b10267ae72e5</td>\n",
       "      <td>US</td>\n",
       "      <td>2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e</td>\n",
       "      <td>UPS</td>\n",
       "      <td>Battery Charger Fault</td>\n",
       "      <td>A battery charger error exists.</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-03-08T14:31:53Z</td>\n",
       "      <td>2021-03-08T14:32:25Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>2579</td>\n",
       "      <td>93</td>\n",
       "      <td>1809</td>\n",
       "      <td>33</td>\n",
       "      <td>1012</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    AssetId  \\\n",
       "70759  6255f030-8744-4d1e-b7ca-f6f3e4e4774d   \n",
       "72736  6255f030-8744-4d1e-b7ca-f6f3e4e4774d   \n",
       "38214  6255f030-8744-4d1e-b7ca-f6f3e4e4774d   \n",
       "85352  6255f030-8744-4d1e-b7ca-f6f3e4e4774d   \n",
       "84853  6255f030-8744-4d1e-b7ca-f6f3e4e4774d   \n",
       "\n",
       "                             organizationid organizationcountrycode  \\\n",
       "70759  c7553c18-7a3d-4728-8d19-b10267ae72e5                      US   \n",
       "72736  c7553c18-7a3d-4728-8d19-b10267ae72e5                      US   \n",
       "38214  c7553c18-7a3d-4728-8d19-b10267ae72e5                      US   \n",
       "85352  c7553c18-7a3d-4728-8d19-b10267ae72e5                      US   \n",
       "84853  c7553c18-7a3d-4728-8d19-b10267ae72e5                      US   \n",
       "\n",
       "                                 locationid AssetType             AlarmLabel  \\\n",
       "70759  2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e       UPS  Battery Charger Fault   \n",
       "72736  2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e       UPS  Battery Charger Fault   \n",
       "38214  2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e       UPS  Battery Charger Fault   \n",
       "85352  2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e       UPS  Battery Charger Fault   \n",
       "84853  2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e       UPS  Battery Charger Fault   \n",
       "\n",
       "                          AlarmMessage Severity    ActivatedTimestamp  \\\n",
       "70759  A battery charger error exists.  WARNING  2021-06-28T09:50:17Z   \n",
       "72736  A battery charger error exists.  WARNING  2021-04-29T05:00:59Z   \n",
       "38214  A battery charger error exists.  WARNING  2021-02-26T00:20:29Z   \n",
       "85352  A battery charger error exists.  WARNING  2021-02-18T16:20:41Z   \n",
       "84853  A battery charger error exists.  WARNING  2021-03-08T14:31:53Z   \n",
       "\n",
       "           ClearedTimestamp  ...  ResolutionTimeMinutes  \\\n",
       "70759  2021-06-28T09:50:50Z  ...               0.550000   \n",
       "72736  2021-04-29T05:01:31Z  ...               0.533333   \n",
       "38214  2021-02-26T00:21:01Z  ...               0.533333   \n",
       "85352  2021-02-18T16:21:13Z  ...               0.533333   \n",
       "84853  2021-03-08T14:32:25Z  ...               0.533333   \n",
       "\n",
       "                  Lemmas_No_Stop_Words                           Tokens  \\\n",
       "70759  ['battery', 'charger', 'fault']  ['battery', 'charger', 'fault']   \n",
       "72736  ['battery', 'charger', 'fault']  ['battery', 'charger', 'fault']   \n",
       "38214  ['battery', 'charger', 'fault']  ['battery', 'charger', 'fault']   \n",
       "85352  ['battery', 'charger', 'fault']  ['battery', 'charger', 'fault']   \n",
       "84853  ['battery', 'charger', 'fault']  ['battery', 'charger', 'fault']   \n",
       "\n",
       "      organizationid_code organizationcountrycode_code  locationid_code  \\\n",
       "70759                2579                           93             1809   \n",
       "72736                2579                           93             1809   \n",
       "38214                2579                           93             1809   \n",
       "85352                2579                           93             1809   \n",
       "84853                2579                           93             1809   \n",
       "\n",
       "       AssetType_code  AlarmLabel_code  AlarmMessage_code  Severity_code  \n",
       "70759              33             1012               1177              4  \n",
       "72736              33             1012               1177              4  \n",
       "38214              33             1012               1177              4  \n",
       "85352              33             1012               1177              4  \n",
       "84853              33             1012               1177              4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row.sort_values(by ='ResolutionTimeMinutes', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9686b253-6a1f-4704-9cd4-3302b70c1642",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = test_row.loc[[5157]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1df0da8-2d93-4364-a41e-4a5a994dbd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssetId</th>\n",
       "      <th>organizationid</th>\n",
       "      <th>organizationcountrycode</th>\n",
       "      <th>locationid</th>\n",
       "      <th>AssetType</th>\n",
       "      <th>AlarmLabel</th>\n",
       "      <th>AlarmMessage</th>\n",
       "      <th>Severity</th>\n",
       "      <th>ActivatedTimestamp</th>\n",
       "      <th>ClearedTimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>ResolutionTimeMinutes</th>\n",
       "      <th>Lemmas_No_Stop_Words</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>organizationid_code</th>\n",
       "      <th>organizationcountrycode_code</th>\n",
       "      <th>locationid_code</th>\n",
       "      <th>AssetType_code</th>\n",
       "      <th>AlarmLabel_code</th>\n",
       "      <th>AlarmMessage_code</th>\n",
       "      <th>Severity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>6255f030-8744-4d1e-b7ca-f6f3e4e4774d</td>\n",
       "      <td>c7553c18-7a3d-4728-8d19-b10267ae72e5</td>\n",
       "      <td>US</td>\n",
       "      <td>2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e</td>\n",
       "      <td>UPS</td>\n",
       "      <td>Battery Charger Fault</td>\n",
       "      <td>A battery charger error exists.</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>2021-06-16T06:05:25Z</td>\n",
       "      <td>2021-06-16T06:05:55Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>['battery', 'charger', 'fault']</td>\n",
       "      <td>2579</td>\n",
       "      <td>93</td>\n",
       "      <td>1809</td>\n",
       "      <td>33</td>\n",
       "      <td>1012</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   AssetId  \\\n",
       "5157  6255f030-8744-4d1e-b7ca-f6f3e4e4774d   \n",
       "\n",
       "                            organizationid organizationcountrycode  \\\n",
       "5157  c7553c18-7a3d-4728-8d19-b10267ae72e5                      US   \n",
       "\n",
       "                                locationid AssetType             AlarmLabel  \\\n",
       "5157  2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e       UPS  Battery Charger Fault   \n",
       "\n",
       "                         AlarmMessage Severity    ActivatedTimestamp  \\\n",
       "5157  A battery charger error exists.  WARNING  2021-06-16T06:05:25Z   \n",
       "\n",
       "          ClearedTimestamp  ...  ResolutionTimeMinutes  \\\n",
       "5157  2021-06-16T06:05:55Z  ...                    0.5   \n",
       "\n",
       "                 Lemmas_No_Stop_Words                           Tokens  \\\n",
       "5157  ['battery', 'charger', 'fault']  ['battery', 'charger', 'fault']   \n",
       "\n",
       "     organizationid_code organizationcountrycode_code  locationid_code  \\\n",
       "5157                2579                           93             1809   \n",
       "\n",
       "      AssetType_code  AlarmLabel_code  AlarmMessage_code  Severity_code  \n",
       "5157              33             1012               1177              4  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "823c41af-473a-49c0-9fe8-ece68635e3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Resolution Time: 1.7662739753723145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patil.anjali/.local/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the test row\n",
    "def preprocess_test_row(test_row, label_encoders, feature_scaler, scaler):\n",
    "    # Encode categorical columns\n",
    "    for column in ['organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity']:\n",
    "        test_row[column] = label_encoders[column].transform(test_row[column].astype(str))\n",
    "    \n",
    "    # Convert timestamps to datetime and extract features\n",
    "    test_row['ActivatedTimestamp'] = pd.to_datetime(test_row['ActivatedTimestamp'])\n",
    "    test_row['ClearedTimestamp'] = pd.to_datetime(test_row['ClearedTimestamp'])\n",
    "    test_row['ActivationHour'] = test_row['ActivatedTimestamp'].dt.hour\n",
    "    test_row['ClearanceHour'] = test_row['ClearedTimestamp'].dt.hour\n",
    "    test_row['ActivationDayOfWeek'] = test_row['ActivatedTimestamp'].dt.dayofweek\n",
    "    test_row['ClearanceDayOfWeek'] = test_row['ClearedTimestamp'].dt.dayofweek\n",
    "    test_row['ResolutionTime'] = (test_row['ClearedTimestamp'] - test_row['ActivatedTimestamp']).dt.total_seconds() / 60\n",
    "\n",
    "    # Select and scale features\n",
    "    features = [\n",
    "        'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "        'month', 'week', 'ActivationHour', 'ClearanceHour',\n",
    "        'ActivationDayOfWeek', 'ClearanceDayOfWeek'\n",
    "    ]\n",
    "    X_test = test_row[features].values\n",
    "    X_test = feature_scaler.transform(X_test)\n",
    "    \n",
    "    return X_test\n",
    "\n",
    "# Preprocess the test row\n",
    "X_test_processed = preprocess_test_row(test_row.copy(), label_encoders, feature_scaler, scaler)\n",
    "\n",
    "# Convert to PyTorch tensor and move to device\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32).to(device)\n",
    "\n",
    "# Make prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).detach().cpu().numpy()\n",
    "\n",
    "# Ensure no negative predictions\n",
    "y_test_pred = np.maximum(y_test_pred, 0)\n",
    "\n",
    "# Convert predicted values back to original scale\n",
    "nn_pred_test_original = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Print the predicted resolution time\n",
    "print(f\"Predicted Resolution Time: {nn_pred_test_original[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4a36bd0-3b58-41d8-9a81-9b1db89e339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with predicted values:\n",
      "                                   AssetId  \\\n",
      "5157  6255f030-8744-4d1e-b7ca-f6f3e4e4774d   \n",
      "\n",
      "                            organizationid organizationcountrycode  \\\n",
      "5157  c7553c18-7a3d-4728-8d19-b10267ae72e5                      US   \n",
      "\n",
      "                                locationid AssetType             AlarmLabel  \\\n",
      "5157  2ceb1e29-6c3a-44f3-8ab0-4f40e54b870e       UPS  Battery Charger Fault   \n",
      "\n",
      "                         AlarmMessage Severity    ActivatedTimestamp  \\\n",
      "5157  A battery charger error exists.  WARNING  2021-06-16T06:05:25Z   \n",
      "\n",
      "          ClearedTimestamp  ...             Lemmas_No_Stop_Words  \\\n",
      "5157  2021-06-16T06:05:55Z  ...  ['battery', 'charger', 'fault']   \n",
      "\n",
      "                               Tokens  organizationid_code  \\\n",
      "5157  ['battery', 'charger', 'fault']                 2579   \n",
      "\n",
      "     organizationcountrycode_code locationid_code  AssetType_code  \\\n",
      "5157                           93            1809              33   \n",
      "\n",
      "      AlarmLabel_code  AlarmMessage_code  Severity_code  \\\n",
      "5157             1012               1177              4   \n",
      "\n",
      "      PredictedResolutionTime  \n",
      "5157                 2.926581  \n",
      "\n",
      "[1 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patil.anjali/.local/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preprocess the test row\n",
    "def preprocess_test_row(test_row, label_encoders, feature_scaler, scaler):\n",
    "    # Encode categorical columns\n",
    "    for column in [ 'organizationcountrycode',  'AssetType', 'AlarmLabel', 'Severity']:\n",
    "        test_row[column] = label_encoders[column].transform(test_row[column].astype(str))\n",
    "    \n",
    "    # Convert timestamps to datetime and extract features\n",
    "    test_row['ActivatedTimestamp'] = pd.to_datetime(test_row['ActivatedTimestamp'])\n",
    "    test_row['ClearedTimestamp'] = pd.to_datetime(test_row['ClearedTimestamp'])\n",
    "    test_row['ActivationHour'] = test_row['ActivatedTimestamp'].dt.hour\n",
    "    test_row['ClearanceHour'] = test_row['ClearedTimestamp'].dt.hour\n",
    "    test_row['ActivationDayOfWeek'] = test_row['ActivatedTimestamp'].dt.dayofweek\n",
    "    test_row['ClearanceDayOfWeek'] = test_row['ClearedTimestamp'].dt.dayofweek\n",
    "    test_row['ResolutionTime'] = (test_row['ClearedTimestamp'] - test_row['ActivatedTimestamp']).dt.total_seconds() / 60\n",
    "\n",
    "    # Select and scale features\n",
    "    features = [\n",
    "        'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "        'month', 'week', 'ActivationHour', 'ClearanceHour',\n",
    "        'ActivationDayOfWeek', 'ClearanceDayOfWeek'\n",
    "    ]\n",
    "    X_test = test_row[features].values\n",
    "    X_test = feature_scaler.transform(X_test)\n",
    "    \n",
    "    return X_test\n",
    "\n",
    "\n",
    "# Preprocess the test row\n",
    "X_test_processed = preprocess_test_row(test_row.copy(), label_encoders, feature_scaler, scaler)\n",
    "\n",
    "# Convert to PyTorch tensor and move to device\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32).to(device)\n",
    "\n",
    "# Make prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).detach().cpu().numpy()\n",
    "\n",
    "# Ensure no negative predictions\n",
    "y_test_pred = np.maximum(y_test_pred, 0)\n",
    "\n",
    "# Convert predicted values back to original scale\n",
    "nn_pred_test_original = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Add the prediction to the test DataFrame\n",
    "test_row['PredictedResolutionTime'] = nn_pred_test_original[0][0]\n",
    "\n",
    "# Print the DataFrame with the predicted values\n",
    "print(\"DataFrame with predicted values:\")\n",
    "print(test_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9119db16-5f74-41c3-90a9-b35e0d9f7a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7748/2934807680.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/2934807680.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/2934807680.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/2934807680.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[column] = le.fit_transform(df_selected[column])\n",
      "/tmp/ipykernel_7748/2934807680.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ActivatedTimestamp'] = pd.to_datetime(df_selected['ActivatedTimestamp'])\n",
      "/tmp/ipykernel_7748/2934807680.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ClearedTimestamp'] = pd.to_datetime(df_selected['ClearedTimestamp'])\n",
      "/tmp/ipykernel_7748/2934807680.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ActivationHour'] = df_selected['ActivatedTimestamp'].dt.hour\n",
      "/tmp/ipykernel_7748/2934807680.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ClearanceHour'] = df_selected['ClearedTimestamp'].dt.hour\n",
      "/tmp/ipykernel_7748/2934807680.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ActivationDayOfWeek'] = df_selected['ActivatedTimestamp'].dt.dayofweek\n",
      "/tmp/ipykernel_7748/2934807680.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ClearanceDayOfWeek'] = df_selected['ClearedTimestamp'].dt.dayofweek\n",
      "/tmp/ipykernel_7748/2934807680.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['ResolutionTime'] = (df_selected['ClearedTimestamp'] - df_selected['ActivatedTimestamp']).dt.total_seconds() / 60\n",
      "[I 2024-06-23 16:13:54,163] A new study created in memory with name: no-name-d7b025b7-323a-4b67-bf6a-dd14178a4e27\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (150, 75) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/patil.anjali/.local/lib/python3.9/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (200, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2024-06-23 16:16:47,997] Trial 0 finished with value: 0.0014806578309663637 and parameters: {'hidden_layers': (200, 100), 'activation': 'relu', 'solver': 'sgd', 'lr': 0.003502283931509678, 'n_epochs': 96}. Best is trial 0 with value: 0.0014806578309663637.\n",
      "[I 2024-06-23 16:19:54,685] Trial 1 finished with value: 8.777465985341776e-05 and parameters: {'hidden_layers': (100, 50), 'activation': 'tanh', 'solver': 'adam', 'lr': 1.3010466204604158e-05, 'n_epochs': 90}. Best is trial 1 with value: 8.777465985341776e-05.\n",
      "[I 2024-06-23 16:21:59,143] Trial 2 finished with value: 7.205037621449688e-05 and parameters: {'hidden_layers': (100, 50), 'activation': 'tanh', 'solver': 'adam', 'lr': 0.0009921666490312344, 'n_epochs': 60}. Best is trial 2 with value: 7.205037621449688e-05.\n",
      "[I 2024-06-23 16:24:47,841] Trial 3 finished with value: 8.913859248531711e-05 and parameters: {'hidden_layers': (100,), 'activation': 'tanh', 'solver': 'adam', 'lr': 0.00018264607981265547, 'n_epochs': 94}. Best is trial 2 with value: 7.205037621449688e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_layers': (100, 50), 'activation': 'tanh', 'solver': 'adam', 'lr': 0.0009921666490312344, 'n_epochs': 60}\n",
      "Neural Network - Test MSE: 7.131243552485371e-05, R²: 0.9841251373291016\n",
      "Original Scale Predictions - Neural Network: [ 2.2933507  3.3710344  3.1168048 27.840858   3.753324 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import optuna\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = [\n",
    "    'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "    'ActivatedTimestamp', 'ClearedTimestamp', 'month', 'week', 'ResolutionTimeMinutes'\n",
    "]\n",
    "df_selected = df_sample[selected_columns]\n",
    "\n",
    "# Convert categorical columns to numerical using Label Encoding\n",
    "label_encoders = {}\n",
    "for column in ['organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity']:\n",
    "    le = LabelEncoder()\n",
    "    df_selected[column] = le.fit_transform(df_selected[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Convert timestamps to datetime and extract features\n",
    "df_selected['ActivatedTimestamp'] = pd.to_datetime(df_selected['ActivatedTimestamp'])\n",
    "df_selected['ClearedTimestamp'] = pd.to_datetime(df_selected['ClearedTimestamp'])\n",
    "df_selected['ActivationHour'] = df_selected['ActivatedTimestamp'].dt.hour\n",
    "df_selected['ClearanceHour'] = df_selected['ClearedTimestamp'].dt.hour\n",
    "df_selected['ActivationDayOfWeek'] = df_selected['ActivatedTimestamp'].dt.dayofweek\n",
    "df_selected['ClearanceDayOfWeek'] = df_selected['ClearedTimestamp'].dt.dayofweek\n",
    "df_selected['ResolutionTime'] = (df_selected['ClearedTimestamp'] - df_selected['ActivatedTimestamp']).dt.total_seconds() / 60\n",
    "\n",
    "# Remove rows with invalid resolution times\n",
    "df_selected = df_selected[(df_selected['ResolutionTime'] >= 0) & (df_selected['ResolutionTime'] <= 10000)]\n",
    "\n",
    "# Remove outliers\n",
    "z_scores = np.abs(stats.zscore(df_selected['ResolutionTimeMinutes']))\n",
    "df_selected = df_selected[z_scores < 3]\n",
    "\n",
    "# Normalize the ResolutionTimeMinutes column\n",
    "scaler = MinMaxScaler()\n",
    "df_selected['ResolutionTimeMinutes'] = scaler.fit_transform(df_selected[['ResolutionTimeMinutes']])\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "    'month', 'week', 'ActivationHour', 'ClearanceHour',\n",
    "    'ActivationDayOfWeek', 'ClearanceDayOfWeek'\n",
    "]\n",
    "X = df_selected[features]\n",
    "y = df_selected['ResolutionTimeMinutes']\n",
    "\n",
    "# Scale the features\n",
    "feature_scaler = StandardScaler()\n",
    "X = feature_scaler.fit_transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device).view(-1, 1)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the PyTorch neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, activation):\n",
    "        super(Net, self).__init__()\n",
    "        layers = []\n",
    "        for units in hidden_layers:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            if activation == 'relu':\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == 'tanh':\n",
    "                layers.append(nn.Tanh())\n",
    "            input_dim = units\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Define the hyperparameter search space\n",
    "        hidden_layers = trial.suggest_categorical('hidden_layers', [(100,), (100, 50), (150, 75), (200, 100)])\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "        solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "        lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "        n_epochs = trial.suggest_int('n_epochs', 50, 100)\n",
    "\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        model = Net(X_train.shape[1], hidden_layers, activation).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        if solver == 'adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(n_epochs):\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        return val_loss\n",
    "    except Exception as e:\n",
    "        print(f\"Error during trial: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Run the optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50, timeout=600)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final model using the best hyperparameters\n",
    "best_hidden_layers = best_params['hidden_layers']\n",
    "best_activation = best_params['activation']\n",
    "best_solver = best_params['solver']\n",
    "best_lr = best_params['lr']\n",
    "best_n_epochs = best_params['n_epochs']\n",
    "\n",
    "model = Net(X_train.shape[1], best_hidden_layers, best_activation).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "if best_solver == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_lr)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_lr)\n",
    "\n",
    "# Training loop for the final model\n",
    "model.train()\n",
    "for epoch in range(best_n_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item() * X_batch.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "# Calculate test R²\n",
    "y_test_pred = model(X_test).detach().cpu().numpy()\n",
    "y_test_true = y_test.detach().cpu().numpy()\n",
    "\n",
    "# Ensure no negative predictions\n",
    "y_test_pred = np.maximum(y_test_pred, 0)\n",
    "\n",
    "test_r2 = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "print(f\"Neural Network - Test MSE: {test_loss}, R²: {test_r2}\")\n",
    "\n",
    "# Convert predicted values back to original scale\n",
    "nn_pred_test_original = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Ensure no negative values after inverse transform\n",
    "nn_pred_test_original = np.maximum(nn_pred_test_original, 0)\n",
    "\n",
    "# Display a few predicted values\n",
    "print(f\"Original Scale Predictions - Neural Network: {nn_pred_test_original[:5].ravel()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "796903d7-088b-4b01-9a2a-bb5b4179120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with predicted values:\n",
      "                                    AssetId  \\\n",
      "55801  289b3e86-2107-4ab7-a2b1-d173f3868866   \n",
      "\n",
      "                             organizationid organizationcountrycode  \\\n",
      "55801  36cafccc-187a-445b-b601-d46eb06bf19f                      FR   \n",
      "\n",
      "                                 locationid AssetType  \\\n",
      "55801  eaa13df7-5840-40c4-bf57-5cae36f7cd37      RPDU   \n",
      "\n",
      "                        AlarmLabel  \\\n",
      "55801  Phase Near Overload Cleared   \n",
      "\n",
      "                                            AlarmMessage Severity  \\\n",
      "55801  Rack PDU 1: A near overload threshold violatio...  WARNING   \n",
      "\n",
      "         ActivatedTimestamp      ClearedTimestamp  ...  \\\n",
      "55801  2021-05-22T07:52:48Z  2021-05-22T07:54:26Z  ...   \n",
      "\n",
      "                         Lemmas_No_Stop_Words  \\\n",
      "55801  ['phase', 'near', 'overload', 'clear']   \n",
      "\n",
      "                                         Tokens  organizationid_code  \\\n",
      "55801  ['phase', 'near', 'overload', 'cleared']                  708   \n",
      "\n",
      "      organizationcountrycode_code locationid_code  AssetType_code  \\\n",
      "55801                           33            9455              28   \n",
      "\n",
      "       AlarmLabel_code  AlarmMessage_code  Severity_code  \\\n",
      "55801             6969              23437              4   \n",
      "\n",
      "       PredictedResolutionTime  \n",
      "55801                 1.425874  \n",
      "\n",
      "[1 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patil.anjali/.local/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess the test row\n",
    "def preprocess_test_row(test_row, label_encoders, feature_scaler, scaler):\n",
    "    # Encode categorical columns\n",
    "    for column in [ 'organizationcountrycode',  'AssetType', 'AlarmLabel', 'Severity']:\n",
    "        test_row[column] = label_encoders[column].transform(test_row[column].astype(str))\n",
    "    \n",
    "    # Convert timestamps to datetime and extract features\n",
    "    test_row['ActivatedTimestamp'] = pd.to_datetime(test_row['ActivatedTimestamp'])\n",
    "    test_row['ClearedTimestamp'] = pd.to_datetime(test_row['ClearedTimestamp'])\n",
    "    test_row['ActivationHour'] = test_row['ActivatedTimestamp'].dt.hour\n",
    "    test_row['ClearanceHour'] = test_row['ClearedTimestamp'].dt.hour\n",
    "    test_row['ActivationDayOfWeek'] = test_row['ActivatedTimestamp'].dt.dayofweek\n",
    "    test_row['ClearanceDayOfWeek'] = test_row['ClearedTimestamp'].dt.dayofweek\n",
    "    test_row['ResolutionTime'] = (test_row['ClearedTimestamp'] - test_row['ActivatedTimestamp']).dt.total_seconds() / 60\n",
    "\n",
    "    # Select and scale features\n",
    "    features = [\n",
    "        'organizationcountrycode', 'AssetType', 'AlarmLabel', 'Severity',\n",
    "        'month', 'week', 'ActivationHour', 'ClearanceHour',\n",
    "        'ActivationDayOfWeek', 'ClearanceDayOfWeek'\n",
    "    ]\n",
    "    X_test = test_row[features].values\n",
    "    X_test = feature_scaler.transform(X_test)\n",
    "    \n",
    "    return X_test\n",
    "\n",
    "\n",
    "# Preprocess the test row\n",
    "X_test_processed = preprocess_test_row(test_row.copy(), label_encoders, feature_scaler, scaler)\n",
    "\n",
    "# Convert to PyTorch tensor and move to device\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32).to(device)\n",
    "\n",
    "# Make prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).detach().cpu().numpy()\n",
    "\n",
    "# Ensure no negative predictions\n",
    "y_test_pred = np.maximum(y_test_pred, 0)\n",
    "\n",
    "# Convert predicted values back to original scale\n",
    "nn_pred_test_original = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "# Add the prediction to the test DataFrame\n",
    "test_row['PredictedResolutionTime'] = nn_pred_test_original[0][0]\n",
    "\n",
    "# Print the DataFrame with the predicted values\n",
    "print(\"DataFrame with predicted values:\")\n",
    "print(test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e427d6-36b4-4b36-8633-0691eccd7d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
